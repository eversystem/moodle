a:349:{s:7:"aborted";s:33:"Testing was aborted due to error.";s:15:"ace_ui_notready";s:42:"Ace editor not ready. Perhaps reload page?";s:16:"addingcoderunner";s:32:"Adding a new CodeRunner Question";s:10:"ajax_error";s:36:"*** AJAX ERROR. DON'T SAVE THIS! ***";s:5:"allok";s:18:"Passed all tests! ";s:9:"allornone";s:64:"Test code must be provided either for all testcases or for none.";s:12:"allornothing";s:22:"All-or-nothing grading";s:17:"allornothing_help";s:458:"If 'All-or-nothing' is checked, all test cases must be satisfied for the submission to earn any marks. Otherwise, the mark is obtained by summing the marks for all the test cases that pass and expressing this as a fraction of the maximum possible mark.

The per-test-case marks can be specified only if the all-or-nothing checkbox is unchecked.

If using a template grader that awards part marks to test cases, 'All-or-nothing' should generally be unchecked.";s:16:"allowattachments";s:17:"Allow attachments";s:21:"allowattachments_help";s:526:"Whether to allow students to add attachments to their submissions and, if so, how many. Attachments are copied into the runtime working directory and a comma-separated list of the names of the attachments is provided  to the template in the Twig variable {{ ATTACHMENTS }}. Warning: allowing attachments could have performance or disk-space implications for the Moodle and Jobe servers with large classes and/or large attachments. The Moodle server, and Jobe servers prior to February 2019, store all attachments indefinitely.";s:16:"allowedfilenames";s:18:"Allowed file names";s:21:"allowedfilenamesregex";s:39:"Allowed file names (regular expression)";s:21:"allowedfilenames_help";s:617:"All uploaded file names must match the given PHP (Perl) regular expression, if non empty. For example, use '.+\\.cpp' to allow any C++ file or '(?!Prog)\\.java' to allow any Java file except 'Prog.java'. Additionally, filenames must contain only alphanumeric characters plus underscore, hyphen and period, must not start with double-underscore ('\_\_') and must not conflict with any of the support file names. The Description is a text message shown to the student to explain what file(s) are expected. Leave empty to display the regular expression itself. Leave both empty to bypass the regular expression checking.";s:19:"allowmultiplestdins";s:21:"Allow multiple stdins";s:6:"answer";s:6:"Answer";s:12:"answerprompt";s:7:"Answer:";s:11:"answer_help";s:271:"A sample answer can be entered here and used for checking by the question author and optionally shown to students during review. It is also used by the bulk tester script. The correctness of a non-empty answer is checked when saving unless 'Validate on save' is unchecked";s:14:"answerrequired";s:33:"Please provide a non-empty answer";s:14:"answertooshort";s:51:"Answer too short. Must be at least {$a} characters.";s:14:"atleastonetest";s:58:"You must provide at least one test case for this question.";s:12:"ace-language";s:12:"Ace language";s:22:"advanced_customisation";s:22:"Advanced customisation";s:15:"answerbox_group";s:10:"Answer box";s:14:"answerboxlines";s:4:"Rows";s:20:"answerbox_group_help";s:274:"Set the number of rows to allocate for the answer box. This sets the minimum height of the User Interface element (e.g. Ace) that controls the answer box. The width is set to fit the window. If the answer overflows the box vertically or horizontally, scrollbars will appear.";s:13:"answerpreload";s:18:"Answer box preload";s:18:"answerpreload_help";s:67:"Text supplied here will be preloaded into the student's answer box.";s:11:"asolutionis";s:27:"Question author's solution:";s:17:"attachmentoptions";s:33:"Attachment options (experimental)";s:19:"attachmentsoptional";s:24:"Attachments are optional";s:19:"attachmentsrequired";s:19:"Require attachments";s:24:"attachmentsrequired_help";s:93:"This option specifies the minimum number of attachments required for a response to be graded.";s:22:"autotagbycategorytitle";s:30:"CodeRunner autotag by category";s:27:"autotagbycategoryindextitle";s:30:"CodeRunner question autotagger";s:16:"badacelangstring";s:23:"Bad Ace-language string";s:10:"badcputime";s:73:"CPU time limit must be left blank or must be an integer greater than zero";s:13:"bad_dotdotdot";s:71:"Misuse of '...'. Must be at end, after two increasing numeric penalties";s:16:"bademptyprecheck";s:53:"Precheck failed with the following unexpected output.";s:18:"bad_empty_splitter";s:62:"Test splitter cannot be empty when using a combinator template";s:17:"badfilenamesregex";s:26:"Invalid regular expression";s:8:"badfiles";s:29:"Disallowed file name(s): {$a}";s:11:"badjsonfunc";s:39:"Unknown JSON embedded func ({$a->func})";s:17:"badjsonorfraction";s:82:"Bad JSON or missing fraction in combinator grader output. Output was: {$a->output}";s:11:"badmemlimit";s:72:"Memory limit must either be left blank or must be a non-negative integer";s:22:"bad_new_prototype_name";s:46:"Illegal name for new prototype: already in use";s:12:"badpenalties";s:78:"Penalty regime must be a comma separated list of numbers in the range [0, 100]";s:11:"badquestion";s:17:"Error in question";s:15:"badrandomintarg";s:40:"Bad argument to JSON @randomint function";s:16:"badrandompickarg";s:40:"Bad argument to JSON @randompic function";s:16:"badsandboxparams";s:74:"'Other' field (sandbox params) must be either blank or a valid JSON record";s:17:"badtemplateparams";s:63:"Template parameters must be either blank or a valid JSON record";s:26:"badtemplateparamsaftertwig";s:69:"Twigging of template parameters yielded invalid JSON: <pre>{$a}</pre>";s:16:"brokencombinator";s:106:"Expected {$a->numtests} test results, got {$a->numresults}. Perhaps excessive output or error in question?";s:20:"brokentemplategrader";s:120:"Bad output from grader: {$a->output}. Your program execution may have aborted (e.g. a timeout or memory limit exceeded).";s:18:"bulkquestiontester";s:235:"The <a href="{$a->link}">bulk tester script</a> tests that the sample answers for all questions in the current context are marked right. Useful only once some questions with sample answers have been added; the initial install has none.";s:20:"bulktestallincontext";s:8:"Test all";s:24:"bulktestcontinuefromhere";s:39:"Run again or resume, starting from here";s:18:"bulktestindextitle";s:23:"CodeRunner bulk testing";s:11:"bulktestrun";s:81:"Run all the question tests for all the questions in the system (slow, admin only)";s:13:"bulktesttitle";s:25:"Testing questions in {$a}";s:20:"coderunnercategories";s:36:"Categories with CodeRunner questions";s:18:"coderunnercontexts";s:34:"Contexts with CodeRunner questions";s:10:"coderunner";s:12:"Program Code";s:34:"coderunner_install_testsuite_title";s:42:"A test suite for CodeRunner sample answers";s:39:"coderunner_install_testsuite_title_desc";s:128:"The <a href="{$a->link}">sample-answer-test script</a> verifies that the questions with sample answers are performing correctly.";s:34:"coderunner_install_testsuite_intro";s:105:"This page allows you to test that the CodeRunner questions with sample answers are functioning correctly.";s:37:"coderunner_install_testsuite_failures";s:17:"Tests that failed";s:37:"coderunner_install_testsuite_noanswer";s:32:"Questions without sample answers";s:15:"coderunner_help";s:203:"In response to a question, which is a specification for a program fragment, function or whole program, the respondent enters source code in a specified computer language that satisfies the specification.";s:15:"coderunner_link";s:24:"question/type/coderunner";s:24:"coderunner_question_type";s:26:"CodeRunner question type: ";s:18:"coderunnersettings";s:19:"CodeRunner settings";s:17:"coderunnersummary";s:107:"Answer is program code that is executed in the context of a set of test cases to determine its correctness.";s:14:"coderunnertype";s:13:"Question type";s:19:"coderunnertype_help";s:143:"Select the programming language and question type. Once a type has been selected, details can be seen in the Question type details panel below.";s:14:"columncontrols";s:12:"Result table";s:19:"columncontrols_help";s:108:"The checkboxes select which columns of the results table should be displayed to the student after submission";s:15:"confirm_proceed";s:100:"If you save this question with 'Customise' unchecked, any customisations made will be lost. Proceed?";s:12:"confirmreset";s:88:"Discard all your work on this question and reset answer box to original preloaded value?";s:7:"cputime";s:16:"TimeLimit (secs)";s:21:"customisationcontrols";s:13:"Customisation";s:9:"customise";s:9:"Customise";s:13:"customisation";s:13:"Customisation";s:9:"datafiles";s:13:"Support files";s:14:"datafiles_help";s:176:"Any files uploaded here will be added to the working directory when the expanded template program is executed. This allows large data or support files to be conveniently added.";s:22:"default_penalty_regime";s:22:"Default penalty regime";s:27:"default_penalty_regime_desc";s:190:"The default penalty regime to apply to new questions, consisting of a comma separated list of penalty percentages, optionally ending in ", ..." to signify an on-going arithmetic progression.";s:7:"display";s:7:"Display";s:20:"downloadquizattempts";s:22:"Download quiz attempts";s:24:"downloadquizattemptshelp";s:315:"Click the appropriate course and/or download button
        for the course and quiz you wish to download. Numbers in parentheses
        after courses are the number of quizzes in the course with at least
        one submission. The numbers in parentheses after the quiz name
        are the numbers of submissions.";s:17:"editingcoderunner";s:29:"Editing a CodeRunner Question";s:24:"empty_new_prototype_name";s:38:"New question type name cannot be empty";s:18:"emptypenaltyregime";s:50:"Penalty regime must be defined (since version 3.1)";s:6:"enable";s:6:"Enable";s:16:"enablecombinator";s:17:"Enable combinator";s:17:"enable_diff_check";s:32:"Enable 'Show differences' button";s:22:"enable_diff_check_desc";s:132:"Present students with a 'Show differences' button if their answer is wrong and an exact-match validator is being used (experimental)";s:19:"enable_sandbox_desc";s:67:"Permit use of the specified sandbox for running student submissions";s:14:"equalitygrader";s:11:"Exact match";s:23:"error_loading_prototype";s:66:"Error loading prototype. Network problems or server down, perhaps?";s:14:"errorstring-ok";s:2:"OK";s:21:"errorstring-autherror";s:27:"Unauthorised to use sandbox";s:19:"errorstring-jobe400";s:32:"Error from Jobe sandbox server: ";s:20:"errorstring-overload";s:71:"Job could not be run due to server overload. Perhaps try again shortly?";s:25:"errorstring-pastenotfound";s:37:"Requesting status of non-existent job";s:23:"errorstring-wronglangid";s:31:"Non-existent language requested";s:24:"errorstring-accessdenied";s:24:"Access to sandbox denied";s:35:"errorstring-submissionlimitexceeded";s:32:"Sandbox submission limit reached";s:28:"errorstring-submissionfailed";s:28:"Submission to sandbox failed";s:19:"errorstring-unknown";s:116:"Unexpected error while executing your code. The sandbox server may be down or overloaded. Perhaps try again shortly?";s:6:"expand";s:6:"Expand";s:11:"expandtitle";s:24:"Show question categories";s:8:"expected";s:15:"Expected output";s:14:"expectedcolhdr";s:8:"Expected";s:13:"expected_help";s:77:"The expected output from the test. Seen by the template as {{TEST.expected}}.";s:18:"exportthisquestion";s:20:"Export this question";s:23:"exportthisquestion_help";s:220:"This will create a Moodle XML export file containing just this one question. One example of when this is useful if you think this question demonstrates a bug in CodeRunner that you would like to report to the developers.";s:5:"extra";s:19:"Extra template data";s:10:"extra_help";s:87:"A sometimes-useful extra text field for use by the template, accessed as {{TEST.extra}}";s:4:"fail";s:4:"Fail";s:5:"fails";s:8:"failures";s:12:"failedhidden";s:42:"Your code failed one or more hidden tests.";s:12:"failedntests";s:30:"Failed {$a->numerrors} test(s)";s:13:"failedtesting";s:15:"Failed testing.";s:8:"feedback";s:8:"Feedback";s:13:"feedback_quiz";s:11:"Set by quiz";s:13:"feedback_show";s:10:"Force show";s:13:"feedback_hide";s:10:"Force hide";s:13:"feedback_help";s:180:"Choose 'Set by quiz' to allow quiz feedback settings to control display of the result table, 'Force show' to show the result table regardless and 'Force hide' to hide it regardless";s:10:"fileheader";s:13:"Support files";s:16:"filenamesexplain";s:11:"Description";s:14:"filenamesregex";s:18:"Regular expression";s:16:"filloutoneanswer";s:158:"You must enter source code that satisfies the specification. The code you enter will be executed to determine its correctness and a grade awarded accordingly.";s:12:"firstfailure";s:29:"First failing test case: {$a}";s:10:"forexample";s:11:"For example";s:11:"globalextra";s:12:"Global extra";s:16:"globalextra_help";s:189:"A field of text for general-purpose use by template authors, like the extra field of each test case, but global to all tests. Available to the template author as {{ QUESTION.globalextra }}.";s:9:"graphhelp";s:749:"- Double click at a blank space to create a new node/state.
- Double click an existing node to "mark" it e.g. as an accept state for Finite State Machines
  (FSMs). Double click again to unmark it.
- Click and drag to move a node.
- Alt click and drag to move a (sub)graph.
- Shift click inside one node and drag to another to create a link.
- Shift click on a blank space, drag to a node to create a start link (FSMs only).
- Click and drag a link to alter its curve.
- Click on a link/node to edit its text.
- Typing _ followed by a digit makes that digit a subscript.
- Typing \epsilon creates an epsilon character (and similarly for \alpha, \beta etc).
- Click on a link/node then press the Delete key to remove it (or function-delete on a Mac).";s:17:"goodemptyprecheck";s:6:"Passed";s:9:"gotcolhdr";s:3:"Got";s:6:"grader";s:6:"Grader";s:7:"grading";s:7:"Grading";s:15:"gradingcontrols";s:16:"Grading controls";s:20:"gradingcontrols_help";s:3552:"The default 'exact match' grader
awards marks only if the output from the run exactly matches the expected value defined
by the testcase. Trailing white space is stripped from all lines, and any trailing
blank lines are deleted, before the
equality test is made.

The near-equality grader is similar except that it
also collapses multiple spaces and tabs to a single space, deletes all blank
lines and converts the strings to lower case.

The 'regular expression' grader uses the 'expected'
field of the test case as a regular expression and tests the output to see
if a match to the expected result can be found anywhere within the output.
To force matching of the entire output, start and end the regular expression
with '\A' and '\Z' respectively. Regular expression matching uses MULTILINE
and DOTALL options.

The 'template grader' option assumes that the output
from the program is actually a
grading result, i.e. that the template not tests *and grades* the student answer.
The only output from such a template program must be a JSON-encoded record.

If the template is a per-test template (i.e., not a combinator), the JSON string must describe a row of the
results table and should contain at least a 'fraction' field, which is multiplied by TEST.mark to decide how
many marks the test case is awarded. It should usually also contain a 'got'
field, which is the value displayed in the 'Got' column of the results table.
The other columns of the results table (testcode, stdin, expected) can also
be defined by the template grading program and will be used instead of the values from
the testcase. As an example, if the output of the program is the string
<tt>{"fraction":0.5, "got": "Half the answers were right!"}</tt>, half marks would be
given for that particular test case and the 'Got' column would display the
text "Half the answers were right!". Other columns can be added to the result
table by adding extra attributes to the JSON record and also to the question's
Result Columns field.

If the template is a combinator, the JSON string output by the template grader
should again contain a 'fraction' field, this time for the total mark,
and may contain zero or more of 'prologuehtml', 'testresults',
'epiloguehtml', 'columnformats' and 'showdifferences'.
The 'prologuehtml' and 'epiloguehtml' fields are html
that is displayed respectively before and after the (optional) result table. The
'testresults' field, if given, is a list of lists used to display some sort
of result table. The first row is the column-header row and all other rows
define the table body. Two special column header values exist: 'iscorrect'
and 'ishidden'. The 'iscorrect' column(s) are used to display ticks or
crosses for 1 or 0 row values respectively. The 'ishidden' column isn't
actually displayed but 0 or 1 values in the column can be used to turn on and
off row visibility. Students do not see hidden rows but markers and other
staff do. If a 'testresults' table is supplied an optional
'columnformats' field can also be supplied. This should be a list
of strings, one per column excluding the 'iscorrect' and the 'ishidden'
columns. The strings specify the format to be used to display the cell values;
currently the only supported formats are '%s' for a normal string display
(which is sanitised and wrapped in a 'pre' element) and '%h' for an html
value that should not be further processed before display.
The 'showdifferences' field turns on display of a 'Show Differences'
button after the results table if the awarded mark fraction is not 1.0.
";s:29:"graph_ui_invalidserialisation";s:30:"GraphUI: invalid serialisation";s:6:"hidden";s:6:"Hidden";s:15:"hidedifferences";s:16:"Hide differences";s:4:"HIDE";s:4:"Hide";s:12:"HIDE_IF_FAIL";s:12:"Hide if fail";s:15:"HIDE_IF_SUCCEED";s:15:"Hide if succeed";s:14:"hiderestiffail";s:17:"Hide rest if fail";s:19:"hoisttemplateparams";s:25:"Hoist template parameters";s:12:"howtogetmore";s:100:"For more detailed information, save the question with 'Validate on save' unchecked and test manually";s:20:"iscombinatortemplate";s:13:"Is combinator";s:11:"ideone_user";s:18:"Ideone server user";s:16:"ideone_user_desc";s:104:"The login name to use when connecting to the deprecated Ideone server (if the ideone sandbox is enabled)";s:11:"ideone_pass";s:22:"Ideone server password";s:16:"ideone_pass_desc";s:102:"The password to use when connecting to the deprecated Ideone server (if the ideone sandbox is enabled)";s:16:"info_unavailable";s:68:"Question type information is not available for customised questions.";s:13:"illegalformat";s:46:"Illegal format ({$a->format}) in columnformats";s:11:"inputcolhdr";s:5:"Input";s:23:"insufficientattachments";s:38:"Not enough attachments, {$a} required.";s:12:"is_prototype";s:16:"Use as prototype";s:11:"jobe_apikey";s:12:"Jobe API-key";s:16:"jobe_apikey_desc";s:141:"The API key to be included in all REST requests to the Jobe server (if required). Max 40 chars. Leave blank to omit the API Key from requests";s:9:"jobe_host";s:11:"Jobe server";s:14:"jobe_host_desc";s:436:"The host name of the Jobe server plus the port number if other than port 80, e.g. jobe.somewhere.edu:4010. The URL for the Jobe request is obtained by default by prefixing this string with http:// and appending /jobe/index.php/restapi/<REST_METHOD>. You may either specify the https:// protocol in front of the host name (e.g. https://jobe.somewhere.edu) if the Jobe server is set behind a reverse proxy which act as an SSL termination.";s:17:"jobe_warning_html";s:319:"<p style='background-color:yellow'>Run using the University of Canterbury's Jobe server. This is for initial testing only. Please set up your own Jobe server as soon as possible. See <a href='https://github.com/trampgeek/moodle-qtype_coderunner/blob/master/Readme.md#sandbox-configuration' target='_blank'>here</a>.</p>";s:8:"language";s:16:"Sandbox language";s:9:"languages";s:9:"Languages";s:14:"languages_help";s:1918:"The sandbox language is the computer language used
to run the submission.
It must be known to the chosen sandbox (if a specific one has been
selected) or to at least one of the enabled sandboxes (otherwise).
This should not usually need altering from the value in the
parent template; tweak it at your peril.

Ace-language is the
language used by the Ace code editor (if enabled) for the student's answer.
By default this is the same as the sandbox language; enter a different
value here only if the template language is different from the language
that the student is expected to write (e.g. if a Python preprocessor is
used to validate a student's C program prior to running it).

Multi-language questions, that is questions that students can answer in
more than one language, are enabled by setting the Ace-language to a comma-separated
list of languages. Students are then presented with a drop-down menu to select
the language in which their answer is written. If exactly one of the languages
has an asterisk ('\*') appended, that language is chosen as the default language,
which is selected as the initial state of the drop-down menu. For example,
an Ace-language value of "C,C++,Java\*,Python3" would allow student to submit in
C, C++, Java or Python3 but the drop-down menu would initially show Java which
would be the default. If no default is specified the
initial state of the drop-down is empty and the student must choose a language.
Multilanguage questions require a special template that uses the {{ANSWER\_LANGUAGE}}
template variable to control how to execute the student code. See the built-in
sample multilanguage question type. The {{ANSWER\_LANGUAGE}} variable is defined
<i>only</i> for multilanguage questions.

If the author wishes to supply a sample answer to a multilanguage question,
they must write it in the default language, if specified, or the
first of the allowed languages otherwise.";s:19:"languageselectlabel";s:8:"Language";s:4:"mark";s:4:"Mark";s:7:"marking";s:15:"Mark allocation";s:12:"markinggroup";s:7:"Marking";s:17:"markinggroup_help";s:1175:"If 'All-or-nothing' is checked, all test cases must be satisfied
for the submission to earn any marks. Otherwise, the mark is obtained
by summing the marks for all the test cases that pass
and expressing this as a fraction of the maximum possible mark.
The per-test-case marks can be specified only if the all-or-nothing
checkbox is unchecked. If using a template grader that awards
part marks to test cases, 'All-or-nothing' should generally be unchecked.

The mandatory penalty regime is a comma-separated list of penalties (each a percent)
to apply to successive submissions. These are absolute, not cumulative. As a
special case the last penalty can be '...' to mean "extend the previous
two penalties as an arithmetic progression up to 100". For example,
<tt>0,5,10,30,...</tt> is equivalent to <tt>0,5,10,30,50,70,90,100</tt>.
If there are more submissions than defined penalties, the last value is used.
Spaces can be used in lieu of commas as a separator.

The default penalty regime can be set site-wide by a system administrator using
Site administration > Plugins > Question types > CodeRunner.

Set the penalty regime to '0' for zero penalties on all submissions.";s:11:"maxfilesize";s:29:"Max allowed file size (bytes)";s:16:"maxfilesize_help";s:166:"Select the maximum file upload size (bytes). Allowing large file uploads with large classes can impact performance and and disk space on both Moodle and Jobe servers.";s:11:"memorylimit";s:13:"MemLimit (MB)";s:14:"missinganswers";s:15:"missing answers";s:13:"missingoutput";s:56:"You must supply the expected output from this test case.";s:16:"missingprototype";s:250:"This question was defined to be of type '{$a->crtype}' but the prototype does not exist, or is non-unique, or is unavailable in this context. You should Cancel and try to (re)install the prototype.
Proceed to edit only if you know what you are doing!";s:17:"missingprototypes";s:18:"Missing prototypes";s:27:"missingprototypewhenrunning";s:66:"Broken question (missing prototype '{$a->crtype}'). Cannot be run.";s:16:"multipledefaults";s:47:"At most one language can be selected as default";s:18:"multipleprototypes";s:44:"Multiple prototypes found for '{$a->crtype}'";s:16:"mustrequirefewer";s:51:"You cannot require more attachments than you allow.";s:18:"nearequalitygrader";s:18:"Nearly exact match";s:18:"nodetailsavailable";s:44:"Select a question type to see detailed help.";s:7:"noqtype";s:25:"No question type selected";s:10:"morehidden";s:35:"Some hidden test cases failed, too.";s:15:"noerrorsallowed";s:59:"Your code must pass all tests to earn any marks. Try again.";s:14:"nonnumericmark";s:16:"Non-numeric mark";s:14:"nosampleanswer";s:16:"No sample answer";s:18:"negativeorzeromark";s:30:"Mark must be greater than zero";s:7:"options";s:7:"Options";s:8:"ordering";s:8:"Ordering";s:13:"overallresult";s:14:"Overall result";s:6:"passes";s:6:"passes";s:13:"penaltyregime";s:24:"(penalty regime: {$a} %)";s:18:"penaltyregimelabel";s:15:"Penalty regime:";s:4:"pass";s:4:"Pass";s:10:"pluginname";s:10:"CodeRunner";s:16:"pluginnameadding";s:28:"Adding a CodeRunner question";s:17:"pluginnameediting";s:29:"Editing a CodeRunner question";s:17:"pluginnamesummary";s:52:"CodeRunner: runs student-submitted code in a sandbox";s:15:"pluginname_help";s:257:"Use the 'Question type' combo box to select the
computer language and question type that will be used to run the student's submission.
Specify the problem that the student must write code for, then define
a set of tests to be run on the student's submission";s:15:"pluginname_link";s:24:"question/type/coderunner";s:8:"precheck";s:8:"Precheck";s:17:"precheck_disabled";s:8:"Disabled";s:14:"precheck_empty";s:5:"Empty";s:17:"precheck_examples";s:8:"Examples";s:17:"precheck_selected";s:8:"Selected";s:12:"precheck_all";s:3:"All";s:13:"precheck_help";s:1109:"If Precheck is enabled, students will have an extra button to the left of the
usual check button to give them a penalty-free run to check their code against
a subset of the question test cases.

If 'Empty' is selected, a single run
will be done with the per-test template using a testcase in which all the
fields (testcode, stdin, expected, etc) are the empty string. Non-empty output
is deemed to be a precheck failure. Use with caution:
some question types will not handle this correctly, e.g. write-a-program questions
that generate output.

If 'Examples' is selected, the code will
be tested against all the tests for which 'use_as_example' has been checked.

If 'Selected' is selected, an extra UI element is added to each test case
to allow the author to select a specific subset of the tests.

If 'All' is selected, all test cases are run (although their behaviour might
be different from the normal Check, if the template code so chooses).

The template can check whether or not the run is a precheck run using the
Twig parameter {{ IS_PRECHECK }}, which is "1" during precheck runs and
"0" otherwise.";s:13:"precheck_only";s:13:"Precheck only";s:19:"precheckingemptyset";s:43:"Prechecking examples, but there aren't any!";s:16:"privacy:metadata";s:69:"The CodeRunner question type plugin does not store any personal data.";s:19:"proceed_at_own_risk";s:65:"Editing a built-in question prototype?! Proceed at your own risk!";s:17:"prototypecontrols";s:11:"Prototyping";s:14:"prototypeusage";s:51:"CodeRunner question prototype usage for course {$a}";s:19:"prototypeusageindex";s:17:"Available courses";s:22:"prototypecontrols_help";s:1062:"If 'Is prototype' is true, this question becomes a prototype for other questions.
After saving, the specified question type name will appear in the dropdown list
of question types. New questions based on this type will then by default inherit
all the customisation attributes specified for this question. Subsequent changes
to this question will then affect all derived questions unless they are
themselves customised, which breaks the connection.

Prototypal inheritance is
single-level only, so this question, when saved as a prototype, loses its
connection to its original base type, becoming a new base type in its own right.
Be warned that when exporting derived questions you must ensure that this
question is included in the export, too, or the derived question will be an
orphan when imported into another system. Also, you are responsible for keeping
track of which questions you are using as prototypes; it is strongly recommended
that you rename the question to something like 'PROTOTYPE_for_my_new_question_type'
to make subsequentmaintenance easier.";s:15:"prototype_error";s:48:"*** PROTOTYPE LOAD FAILURE. DON'T SAVE THIS! ***";s:22:"prototype_load_failure";s:25:"Error loading prototype: ";s:10:"prototypeQ";s:13:"Is prototype?";s:16:"qtype_c_function";s:1242:"<p>A question type for C write-a-function questions.
The student answer is expected to be a complete C function, but it can optionally
be preceded by other self-contained C code such as preprocessor directives and
support functions.</p>
<p>The test code for such questions typically calls the student function with
some test arguments and prints the result, such as
<pre>printf("%d\n", someIntFunction(blah1, blah2))</pre>
The test case's <i>Expected</i> field is the expected output from the test.</p>
<p>
If there is no standard input supplied for any of the test cases, a single
test program is constructed, consisting of:</p>
<ol>
<li>The following standard #includes: stdlib.h, ctype.h, string.h, stdbool.h, math.h</li>
<li>The student answer.</li>
<li>A sequence of blocks wrapped in braces for each of the given test cases.
Each block contains just the test case's test code. There is also a <i>printf</i>
statement added between code blocks to print a special separator that is used
to split the output back into individual test case outputs.</li>
</ol>
<p>However, if any of the test cases has non-empty standard input, multiple test
programs are run, one for each test case.
</p><p>The test case's <i>extra</i> field is ignored.</p>";s:18:"qtype_cpp_function";s:1301:"<p>A question type for C++ write-a-function questions.
The student answer is expected to be a complete C++ function, but it can optionally
be preceded by other self-contained C++ code such as preprocessor directives and
support functions.</p>
<p>In each test case, the test code for such questions typically calls the student function with
some test arguments and prints the result, such as
<pre>cout << someIntFunction(blah1, blah2))</pre>
The test case's <i>Expected</i> field is the expected output from the test.
<p>
If there is no standard input supplied for any of the test cases, a single
test program is constructed, consisting of:</p>
<ol>
<li>The following standard #includes: iostream, fstream, string, math, vector and algorithm</li>
<li><code>using namespace std;</code></li>
<li>The student answer</li>
<li>A sequence of blocks wrapped in braces for each of the given test cases.
Each block consists of the test case's <i>extra</i> field (usually empty)
followed by the test code. There is also a <i>printf</i>
statement added between code blocks to print a special separator that is used
to split the output back into individual test case outputs.</li>
</ol>
<p>However, if any of the test cases has non-empty standard input, multiple test
programs are run, one for each test case.
</p>";s:15:"qtype_c_program";s:698:"<p>Used for C write-a-program questions, where
there is no per-test-case code, and the different tests just use different
standard input (stdin) data. The student answer is expected to be a complete
runnable program, which is run as-is, without modification by CodeRunner,
once for each test case. The values of the test code and extra fields of each
test case are ignored.</p><p>If you need to set special compile or link
arguments for the question, you can customise it (click the Customise
checkbox), open the <i>Advanced customisation</i> section, and enter suitable
values into the <i>Sandbox &gt; Parameters</i> field. For example<pre>
{"linkargs":["-lm"]}</pre>to link with the math library.";s:17:"qtype_cpp_program";s:379:"<p>Used for C++ write-a-program questions, where
there is no per-test-case code, and the different tests just use different
standard input (stdin) data. The student answer is expected to be a complete
runnable program, which is run as-is, without modification by CodeRunner,
once for each test case. The values of the test code and extra fields of each
test case are ignored.</p>";s:20:"qtype_directed_graph";s:4522:"<p>A python3 question type that asks the student to draw
a directed graph to satisfy some specification. The question author has to write
Python3 code to check the resulting graph.</p><p>Note that it is not actually
necessary to use this question type for directed graphs, as the functionality
is mainly provided by the GraphUI plugin. If the graph pre-processing performed
by this question type does not suit your needs, you can instead just use a normal
Python3 question (or any other language), set the UI to GraphUI, and analyse
the JSON-serialised version of the graph (the Twig STUDENT_ANSWER&nbsp; variable)
yourself. However, this question type does provide an example of how to use the
GraphUI plugin. Click <i>Customise</i>&nbsp;to see the template code.</p>
<p>The specification will ask the student to draw a directed graph to satisfy
certain requirements. It might for example be a DFA (deterministic finite-state
automaton) or a Turning machine. The test case code and/or the extra code will
then analyse the graph and print a message to the student, such as OK if the
graph is correct or a suitably informative error message otherwise.</p>
<p>The template for this question analyses the JSON-serialised graph, extracting
its topology in the form of an adjacency dictionary&nbsp;<i>graph</i>. This
variable is available to the test or extra code in the test case. Keys in the
dictionary are node names, if given, or arbitrary node identifying labels of
the form #1, #2 etc otherwise. Values in the dictionary are lists of outgoing
edges, sorted by neighbour node name or identifier, each edge being a tuple
(neighbourId, edgeLabel).</p><p>Each entry in the adjacency list is of the form
(nodeNameOrId, neighbours) where neighbours is a list of tuples
(neighbourNodeNameOrId, edgeLabel). If nodes are given names, those are used
as node identifiers, otherwise the names #1, #2 etc are used. The adjacency
list and the neighbour list are both sorted in order of node name or identifier.</p>
<p>The template is a combinator one: the <i>testcode</i>&nbsp;and
<i>extra</i>&nbsp;code are both executed for each test case.</p><p>As a simple
example, if the specification were just "Draw a directed graph with two nodes
labelled A and B, with an edge from A to B", a suitable test case (albeit with
unhelpful error output) might be:</p><pre>
if set(graph.keys()) == {'A', 'B'} and len(graph['A']) == 1 and len(graph['B']) == 0 and graph['A'][0][0] == 'B':
    print('OK')
else:
    print('Nope')
</pre>
<p>Alternatively, there could be a set of test cases, each one checking
one of the aspects of the specification. For example, the first test case might
print the sorted keys, expecting to see 'A', 'B'. The second test case might
print the outgoing edges from node 'A', and so on.</p>
<p>The question takes the following template parameters, all of which are recognised
by the GraphUI plugin and control its behaviour.</p>
<p><ul>
<li>isfsm. True if the graph is of a Finite State Machine. If true, the graph
can contain an incoming edge from nowhere (the start edge). Default: true.</li>
<li>isdirected. True if edges are directed. Default: true.</li>
<li>noderadius. The radius of a node, in pixels. Default: 26.</li>
<li>fontsize. The font size used for node and edge labels. Default: 20 points.</li>
<li>helpmenutext. A string to be used in lieu of the default Help info, if supplied.
No default.</li>
<li>locknodepositions. True to prevent the user from moving nodes. Useful when the
answer box is preloaded with a graph that the student has to annotate by
changing node or edge labels or by adding/removing edges. Note, though that
nodes can still be added and deleted.</li>
<li>locknodeset. True to prevent user from adding or deleting nodes or toggling
the accept-state (from fsm graphs).</li>
<li>locknodelabels. True to prevent the user from editing node labels (including
newly added nodes).</li>
<li>lockedgepositions. True to prevent the user from dragging edges to change
their curvature. Possibly useful if the
answer box is preloaded with a graph that the student has to annotate by
changing node or edge labels or by adding/removing edges. Also ensures that
edges added by a student are straight, e.g. to draw a polygon on a set of
given points. Note, though that
edges can still be added and deleted.</li>
<li>lockedgeset. True to prevent the user from adding or removing edges.</li>
<li>lockedgelabels. True to prevent the user from editing edge labels (including
newly added ones</li>
</ul></p>";s:16:"qtype_java_class";s:1337:"<p>A Java write-a-class question, where the student submits a
complete class as their answer. Each test will  typically instantiate an object of the specified
class and perform one or more tests on it. It is not a combinator question type, meaning that
each test case runs as a separate sandbox program.
</p><p>The program generated for each test case consists of the student answer, with
the <i>public</i>&nbsp;attribute stripped if present. That (now local)
class definition is followed by a public <i>__Tester__&nbsp;</i>&nbsp;class that
has a <i>main</i>&nbsp;method that instantiates the Tester class and calls its
<i>runTests</i>&nbsp;method. The <i>runTests</i>&nbsp;method simply contains the
test case code. See the template for clarification.</p><p>It should be noted that
the algorithm used to strip the public attribute from the student-supplied class
is simplistic; it only works if the words <i>public class</i>&nbsp;exist exactly
once in the student code, separated by a single space.</p>
<p>The test case extra field is ignored.</p>
<p>This question type is inefficient if there are many test, as a separate
compile-and-execute job is sent to the sandbox for each test case. This could be
resolved by writing a combinator-style question type. See the coderunner
documentation (coderunner.org.nz) for more information.</p>";s:17:"qtype_java_method";s:603:"<p>Used for Java write-a-method questions where the
student is asked to write a method that is essentially a standalone function.
The author-supplied test is typically just one or two lines of code that
(apparently) just call the student supplied method, as in C. Under the hood, the
template constructs a Main class containing the student-supplied method
(and any other support methods, if they choose to write them) plus a 'runTests'
method that wraps the testcase(s). The main function for the class constructs an
instance of Main and calls its runTests method. See the template code for details.</p>";s:18:"qtype_java_program";s:715:"<p>A Java write-a-program question where the student
submits a complete program as their answer. The program is compiled and executed for each
test case. There is no test code, just stdin test data, though this isn't
actually checked: caveat emptor. The extra fields of the test cases are likewise
ignored.</p>
<p>This question type becomes very inefficient if there are many test cases, since
each one necessitates a full compile-and-execute cycle on the Jobe server. It is
possible to wrap all tests into a single Python job that is sent to the sandbox
server and compiles the program just once, then runs it on each test case.
For details of this approach, see the question author forum on
coderunner.org.nz.</p>";s:19:"qtype_multilanguage";s:642:"<p>A "write a program" style
of question in which the student can submit an answer in any of the
following languages: C, C++, Java, Python3. The student's question answer
box has a drop-down menu at the top, with which the student must select
the language in which their answer is written.</p>
<p>Further languages can be added, if supported on the Jobe server, by
adding the language name to the <i>AceLang</i> field of the question edit
form and then extending the template (q.v.) to handle the new language.</p>
<p>The submitted program code is run as-is for each test case. The testcode
and extra fields of each test case are ignored.</p>";s:12:"qtype_nodejs";s:536:"<p>A JavaScript question type, run using nodejs. The
test program to be executed starts with the student answer. That is followed
by each of the test case codes in turn, with a separator string being printed
between them. However, if there is any standard input present for any of the
test cases, a separate test run will be done for each test case.</p><p>
If there is a risk of side-effects from a test case affecting later test cases
you can add standard input to any one of the test cases to force the one-run-per-test-case
mode.</p>";s:21:"qtype_octave_function";s:598:"<p>A question type that specifies an
Octave function, which the student has to submit in its entirety. Each test
case will typically call the student function with test arguments and print
the result or some value derived from it. If there is no standard input present
in any of the questions, the program consists of the student answer, the
statement <code>format free</code> and the test code from each test case,
plus an extra <i>disp</i> statement to print a separator string between
test case outputs.</p><p>If there is any standard input present, each test
case is instead run separately.</p>";s:21:"qtype_pascal_function";s:331:"<p>A Pascal question type where the student
 is asked to write a procedure or function. The program to be run consists of
 the student answer followed by the CodeRunner <i>testcode</i> wrapped
 in <code>begin ... end.</code>.<br>
 This is not a combinator question type, so a separate jobe run will be done
 for each test case.</p>";s:20:"qtype_pascal_program";s:253:"<p>A Pascal question type where the student
 answer is a complete Pascal program. The program is compiled and run once for
 each test case, using the standard input provided in the test case and
 ignoring the <i>testcode</i> and <i>extra</i> fields.</p>";s:9:"qtype_php";s:801:"<p>A php question in which the student submission is
php code. In the simplest case, the student code will start with</p><pre>
&lt;?php
</pre>but <i>will not close the PHP tag</i>. The reason for the non-closure
can be seen by inspecting the template: the student answer is followed by each
of the test case test codes. If instead you wish the student code to end by
closing the PHP tag, you should edit the template to re-open the PHP tag before
the sequence of tests.
</p><p>The output from each test case, which should match the test case
<i>expected</i> field, will be the output from the student's PHP code
(including any content outside the scope of &lt;?php...?&gt; tags) plus the
output from the test code.</p><p>Inspect the template code (by clicking
<i>Customise</i>) to understand this.</p>";s:13:"qtype_python2";s:1083:"<p>A Python2 question type, which can handle
write-a-function, write-a-class or write-a-program question types. For each
test case, the student-answer code is executed followed by the test code.
Thus, for example, if the student is asked to write a function definition,
their definition will be executed first, followed by the author-supplied
test code, which will typically call the function and print the result or
some value derived from it.</p>
<p>If there are no standard inputs defined for all test cases, the question
actually wraps all the tests
into a single run, printing a separator string between each test case output.
Please be aware that this isn't necessarily the same as running each test
case separately. For example, if there are any global variables defined by
the student code, these will hold their values across the multiple runs.
If this is likely to prove a problem, the easiest work-around is to define
one of the test case standard input fields to be a non-empty value - this
forces CodeRunner into a fallback mode of running each test case separately.</p>";s:13:"qtype_python3";s:1083:"<p>A Python3 question type, which can handle
write-a-function, write-a-class or write-a-program question types. For each
test case, the student-answer code is executed followed by the test code.
Thus, for example, if the student is asked to write a function definition,
their definition will be executed first, followed by the author-supplied
test code, which will typically call the function and print the result or
some value derived from it.</p>
<p>If there are no standard inputs defined for all test cases, the question
actually wraps all the tests
into a single run, printing a separator string between each test case output.
Please be aware that this isn't necessarily the same as running each test
case separately. For example, if there are any global variables defined by
the student code, these will hold their values across the multiple runs.
If this is likely to prove a problem, the easiest work-around is to define
one of the test case standard input fields to be a non-empty value - this
forces CodeRunner into a fallback mode of running each test case separately.</p>";s:22:"qtype_undirected_graph";s:4094:"<p>A python3 question type that asks the student to draw
an undirected graph to satisfy some specification. The question author has to write
Python3 code to check the resulting graph.</p><p>Note that it is not actually
necessary to use this question type for undirected graphs, as the functionality
is mainly provided by the GraphUI plugin. If the graph pre-processing performed
by this question type does not suit your needs, you can instead just use a normal
Python3 question (or any other language), set the UI to GraphUI, and analyse
the JSON-serialised version of the graph (the Twig STUDENT_ANSWER&nbsp; variable)
yourself. However, this question type does provide an example of how to use the
GraphUI plugin. Click <i>Customise</i>&nbsp;to see the template code.</p>
<p>The specification will ask the student to draw an undirected graph to satisfy
certain requirements, e.g. a graph representation of a set of towns connected
by two-way roads. The test case code and/or the extra code will
then analyse the graph and print a message to the student, such as OK if the
graph is correct or a suitably informative error message otherwise.</p>
<p>The template for this question analyses the JSON-serialised graph, extracting
its topology in the form of an adjacency dictionary&nbsp;<i>graph</i>. This
variable is available to the test or extra code in the test case. Keys in the
dictionary are node names, if given, or arbitrary node identifying labels of
the form #1, #2 etc otherwise. Values in the dictionary are lists of edges,
sorted by neighbour node name or identifier, each edge being a tuple
(neighbourId, edgeLabel).</p><p>Each entry in the adjacency list is of the form
(nodeNameOrId, neighbours) where neighbours is a list of tuples
(neighbourNodeNameOrId, edgeLabel). If nodes are given names, those are used
as node identifiers, otherwise the names #1, #2 etc are used. The adjacency
list and the neighbour list are both sorted in order of node name or identifier.</p>
<p>The template is a combinator one: the <i>testcode</i>&nbsp;and
<i>extra</i>&nbsp;code are both executed for each test case.</p><p>As a simple
example, if the specification were just "Draw an undirected graph with two nodes
labelled A and B, with an edge between the two nodes", a suitable test case (albeit with
unhelpful error output) might be:</p><pre>
if set(graph.keys()) == {'A', 'B'} and len(graph['A']) == 1 and len(graph['B']) == 1 and graph['A'][0][0] == 'B':
    print('OK')
else:
    print('Nope')
</pre>
<p>Alternatively, there could be a set of test cases, each one checking
one of the aspects of the specification. For example, the first test case might
print the sorted keys, expecting to see 'A', 'B'. The second test case might
print the edges connected to node 'A', and so on.</p>
<p>The question takes the following template parameters, all of which are recognised
by the GraphUI plugin and control its behaviour.</p>
<p><ul>
<li>isfsm. True if the graph is of a Finite State Machine. If true, the graph
can contain an incoming edge from nowhere (the start edge). Default: false.</li>
<li>isdirected. True if edges are directed. Default: false.</li>
<li>noderadius. The radius of a node, in pixels. Default: 26.</li>
<li>fontsize. The font size used for node and edge labels. Default: 20 points.</li>
<li>helpmenutext. A string to be used in lieu of the default Help info, if supplied.
No default.</li>
<li>locknodes. True to prevent the user from moving nodes. Useful when the
answer box is preloaded with a graph that the student has to annotate by
changing node or edge labels or by adding/removing edges. Note, though that
nodes can still be added and deleted.</li>
<li>lockedges. True to prevent the user from dragging edges to change
their curvature. Possibly useful if the
answer box is preloaded with a graph that the student has to annotate by
changing node or edge labels or by adding/removing edges. Also ensures that
edges added by a student are straight, e.g. to draw a polygon on a set of
given points. Note, though that
edges can still be added and deleted.</li>
</ul></p>";s:21:"qtype_python3_w_input";s:1905:"<p>A Python3 question type, which can handle
write-a-function, write-a-class or write-a-program question types. It differs
from the slightly simpler <i>python3</i> question type in that the usual
python3 <i>input</i> function is replaced with a custom version that echoes
standard input to standard output as it is consumed. This results in the output
mimicking that which is seen by students when testing with keyboard input.
It is recommended instead for the <i>python3</i> question type for any
questions that involve calls to <i>input</i> in introductory programming
courses, where students are likely to be confused by the non-echoing of
standard input when taken from a file.</p><p>A slight downside of this question
type compared to the <i>python3</i> question type is that any error messages
in the student code will have confusing line numbers, since the substitute
input function is inserted before the student code.</p>
<p>For each
test case, the student-answer code is executed followed by the test code.
Thus, for example, if the student is asked to write a function definition,
their definition will be executed first, followed by the author-supplied
test code, which will typically call the function and print the result or
some value derived from it.</p>
<p>If there are no standard inputs defined for all test cases, the question
actually wraps all the tests
into a single run, printing a separator string between each test case output.
Please be aware that this isn't necessarily the same as running each test
case separately. For example, if there are any global variables defined by
the student code, these will hold their values across the multiple runs.
If this is likely to prove a problem, the easiest work-around is to define
one of the test case standard input fields to be a non-empty value - this
forces CodeRunner into a fallback mode of running each test case separately.</p>";s:9:"qtype_sql";s:1129:"<p>An <b>experimental</b> SQL question type, using sqlite3,
 run from Python3. sqlite3 must be installed on the Jobe server for this question
 type.</p>
 <p>The working directory is searched for files with an extension '.db'. If
 there is only one such file, it is used as the sqlite3 database for all tests.
 Multiple .db files currently issues an error message; a possible extension is
 to use different db files for each test, e.g. in sorted order.</p>
 <p>For each test, an sqlite3 command script of the form</p>
 <pre>.mode column<br>.headers on<br>&lt;code in extra&gt;<br>&lt;student answer&gt;<br>&lt;testcode&gt;</pre>
 <p>is run.</p>
 <p>A fresh copy of the db file is used for each test case.&nbsp;</p>
 <p>A template parameter <i>columnwidths</i>&nbsp;can be used to set the report
 column widths. By default sqlite3 sets each column width to be the maximum of
 three numbers: 10, the width of the header, and the width of the first row of data.
 A template string like</p><pre><code>{"columnwidths": [10, 50, 10, 5]}
</code></pre>
<p>will instead use column widths of 10, 50, 10 and 5 for the first four columns.</p>";s:9:"qtypehelp";s:16:"Help with q-type";s:18:"questioncheckboxes";s:13:"Customisation";s:23:"questioncheckboxes_help";s:327:"To customise the question type, e.g. to edit the question templates or
sandbox parameters, click the 'Customise'
checkbox and read the help available on the newly-visible form elements for
more information.

If the template-debugging checkbox is clicked, the program generated
for each testcase will be displayed in the output.";s:17:"questionloaderror";s:23:"Failed to load question";s:15:"questionpreview";s:16:"Question preview";s:12:"questiontype";s:13:"Question type";s:21:"question_type_changed";s:103:"Changing question type. Click OK to reload customisation fields, Cancel to retain your customised ones.";s:17:"questiontype_help";s:543:"Select the particular type of question.

The combo-box selects one of the built-in types, each of which
specifies a particular language and, sometimes, a sandbox in which
the program will be executed. Each question type has a
template that defines how the executable program is built from the
testcase data and the student answer.

The template can be viewed and optionally customised by clicking
the 'Customise' checkbox.

If the template-debugging checkbox is clicked, the program generated
for each testcase will be displayed in the output.";s:19:"questiontypedetails";s:21:"Question type details";s:21:"questiontype_required";s:36:"You must select the type of question";s:15:"qWrongBehaviour";s:194:"Please use Adaptive Behaviour for all CodeRunner questions, or there can be massive performance hits. For example, all questions on a page will need to be regraded when the page is re-displayed.";s:11:"regexgrader";s:18:"Regular expression";s:19:"replacedollarscount";s:49:"This category contains {$a} CodeRunner questions.";s:22:"replaceexpectedwithgot";s:96:"Click on the &lt;&lt; button to replace the expected output of this testcase with actual output.";s:13:"resultcolumns";s:14:"Result columns";s:5:"reset";s:12:"Reset answer";s:10:"resethover";s:60:"Discard changes and reset answer to original preloaded value";s:18:"resultcolumnheader";s:6:"Result";s:18:"resultcolumns_help";s:1996:"By default the result table displays the testcode, stdin, expected and got
columns, provided the columns are not empty. You can change the default, and/or
the column headers by entering a value for the resultcolumns (leave blank for
the default behaviour).

If supplied, the resultcolumns field must be a
JSON-encoded list of column specifiers. Each column specifier is itself a list,
typically with just two or three elements. The first element is the column
header, the second element is the field from the TestResult object being
displayed in the column and the optional third element is an sprintf format
string used to display the field.

The fields available in the standard
TestResult object are: testcode, stdin, expected, got, extra, awarded, and mark.
testcode, stdin, expected and extra are the fields from the testcase while got
is the actual output generated and awarded and mark are the actual awarded mark
and the maximum mark for the testcase respsectively.

Per-test template-graders may
add their own fields, which can also be selected for display. It is also
possible to combine multiple fields into a column by adding extra fields to the
specifier: these must precede the sprintf format specifier, which then becomes
mandatory. For example, to display a Mark Fraction column in the form 0.74/1.00,
say, a column format specifier of ["Mark Fraction", "awarded", "mark",
"%.2f/%.2f"] could be used.

As a further special case, a format of %h means that
the test result field should be taken as ready-to-output HTML and should not be
subject to further processing; this is useful only with custom-grader templates
that generate HTML output, such as SVG graphics.

The default value of
resultcolumns is [["Test", "testcode"],["Input", "stdin"], ["Expected",
"expected"], ["Got", "got"]].

The setting of the resultcolumns field has no effect if a combinator template
grader is being used. The question author is then responsible for formatting
the result table in any desired way.";s:20:"resultcolumnsnotjson";s:47:"Result columns field is not a valid JSON string";s:20:"resultcolumnsnotlist";s:66:"Result columns field must a JSON-encoded list of column specifiers";s:19:"resultcolumnspecbad";s:78:"Invalid column specifier found: each one must be a list of two or more strings";s:18:"resultstring-norun";s:6:"No run";s:29:"resultstring-compilationerror";s:17:"Compilation error";s:25:"resultstring-runtimeerror";s:5:"Error";s:22:"resultstring-timelimit";s:19:"Time limit exceeded";s:20:"resultstring-success";s:2:"OK";s:24:"resultstring-memorylimit";s:21:"Memory limit exceeded";s:27:"resultstring-illegalsyscall";s:21:"Illegal function call";s:26:"resultstring-internalerror";s:42:"CodeRunner error (IE): please tell a tutor";s:27:"resultstring-sandboxpending";s:42:"CodeRunner error (PD): please tell a tutor";s:26:"resultstring-sandboxpolicy";s:42:"CodeRunner error (BP): please tell a tutor";s:28:"resultstring-sandboxoverload";s:48:"Sandbox server overload. Perhaps try again soon?";s:24:"resultstring-outputlimit";s:16:"Excessive output";s:32:"resultstring-abnormaltermination";s:20:"Abnormal termination";s:10:"run_failed";s:19:"Failed to run tests";s:23:"sampleanswerattachments";s:25:"Sample answer attachments";s:28:"sampleanswerattachments_help";s:62:"If the sample answer needs attachments files, upload them here";s:15:"sandboxcontrols";s:7:"Sandbox";s:20:"sandboxcontrols_help";s:2039:"
Select what sandbox to use for running the student submissions.
DEFAULT uses the highest priority sandbox available for the chosen language.
Since Jobe has replaced all sandbox
types except the deprecated 'ideonesandbox',
the value 'jobesandbox' is recommended for normal use, and results in better
error messages if the Jobe server is down.

You can also set the
maximum CPU time in seconds  allowed for each testcase run and the maximum
memory a single testcase run can consume (MB). A blank entry uses the sandbox's
default value (typically 5 secs for the CPU time limit and a language-dependent
amount of memory), but the defaults may not be suitable for resource-demanding
programs. A value of zero for the maximum memory results in no limit being
imposed. The amount of memory specified here is the total amount needed for
the run including all libraries, interpreters, VMs etc.

The 'Parameters' entry
is used to pass further sandbox-specific data, such as compile options and
API-keys. It should generally be left blank but if non-blank it must be a valid
JSON record. In the case of the jobe sandbox, available attributes include
disklimit, streamsize, numprocs, compileargs, linkargs and interpreterargs. For
example <tt>{"compileargs":["-std=c89"]}</tt> for a C question would force C89
compliance and no other C options would be used. See the jobe documentation
for details. Some sandboxes (e.g. the deprecated Ideone sandbox) may silently ignore any or all of
these settings.

If the sandbox is set to 'jobesandbox', the jobe host to use for testing the
question is
usually as specified via the administrator settings for the CodeRunner plugin.
However, it is possible to select a different jobeserver by defining a 'jobeserver'
parameter and also, optionally, a 'jobeapikey' parameter. For example, if the
'Parameters' field is set to <tt>{"jobeserver": "myspecialjobe.com"}</tt>, the run
will instead by submitted to the server "myspecialjobe.com". Warning: this
feature is still experimental and may change in the future.
";s:12:"sandboxerror";s:53:"Error from the sandbox [{$a->sandbox}]: {$a->message}";s:13:"sandboxparams";s:10:"Parameters";s:32:"seethisquestioninthequestionbank";s:38:"See this question in the question bank";s:4:"SHOW";s:4:"Show";s:11:"showcolumns";s:13:"Show columns:";s:16:"showcolumns_help";s:159:"Select which columns of the results table should
be displayed to students. Empty columns will be hidden regardless.
The defaults are appropriate for most uses.";s:15:"showdifferences";s:16:"Show differences";s:10:"showsource";s:18:"Template debugging";s:17:"sourcecodeallruns";s:37:"Debug: source code from all test runs";s:5:"stdin";s:14:"Standard Input";s:10:"stdin_help";s:70:"The standard input to the test, seen by the template as {{TEST.stdin}}";s:14:"student_answer";s:14:"Student answer";s:14:"supportscripts";s:15:"Support scripts";s:13:"syntax_errors";s:15:"Syntax Error(s)";s:20:"table_ui_invalidjson";s:37:"Table UI: invalid JSON serialisation.";s:29:"table_ui_invalidserialisation";s:32:"Table UI: invalid serialisation.";s:22:"table_ui_missingparams";s:72:"Table UI needs template parameters table_num_columns and
table_num_rows.";s:8:"template";s:8:"Template";s:16:"template_changed";s:77:"Per-test template changed - disable combinator? ['Cancel' leaves it enabled.]";s:16:"templatecontrols";s:17:"Template controls";s:21:"templatecontrols_help";s:2296:"Checking the 'Is combinator' checkbox
specifies that the template is a combinator template, which combines (or attempts
to combine) the student answer plus all test cases into a single run. If this
checkbox is checked, you will also need to define the value of the test_splitter_re
field, which is the PHP regular expression used to split the output from the
program run back into a set of individual test runs. However, you do not need
to define this if you're also using a template grader, as in that case the
template code is responsible for splitting the output itself, and grading it.

Combinator templates do not get passed a TEST Twig variable. Instead they
receive a variable TESTCASES, which is a list of all the tests in the
question. The program produced by the template is generally assumed to combine the
STUDENT_ANSWER and all the TESTCASES into a single program which, when it is run,
outputs the test results from each test case, separated by a unique string.
The separator string is defined by a regular expression given by the form
field 'test_splitter_re' below.

However, if testcases have standard input defined, combinator templates become
problematic. If the template constructs a single program, what should the standard
input be? The simplest (and default) solution is to
run the test cases one at a time, using the combinator template to build
each program, passing it a TESTCASES variable containing just a single test.
This 'trick' allows the combinator template to serve a dual role: it behaves
as a per-test-case template (with a 1-element TESTCASES array) when the question
author supplies standard input but as a proper combinator (with an n-element
TESTCASES array) otherwise. To change this behaviour so that the combinator
receives all testcases, even when stdin is present, check the 'Allow multiple
stdins' checkbox.

If a run of the combinator program results in any output to stderr, that
is interpreted as a run error. To ensure the student gets credit for as many
valid tests as possible, the system behaves as it does when standard input
is present, falling back to running each test separately. This does not
apply to combinator graders, however, which are required to deal with all
runtime errors themselves and must always return a valid JSON outcome.";s:13:"templateerror";s:14:"TEMPLATE ERROR";s:14:"templategrader";s:15:"Template grader";s:13:"template_help";s:1915:"The template defines the program(s) that run in the sandbox for a given
student answer and test(s). There are two
types of template:

* a per-test template, which defines a program to be run for a single test case and,
* a 'combinator' template which defines a program that combines all the different cases into a single program.

The 'is_combinator' checkbox is left unchecked for a per-test template and is
set checked for a combinator template. The rest of this help panel assumes you
are using a per-test template; see the full documentation for the use of
combinator templates.

The template is processed
by the Twig template engine (see http://twig.sensiolabs.org)
in a context in which STUDENT_ANSWER is the student's
response and TEST.testcode is the code for the current testcase. These values
(and other testcase values like TEST.expected, TEST.stdin, TEST.mark)
can be inserted into the template by enclosing them in double braces, e.g.
<tt>{{TEST.testcode}}</tt>. For use within literal strings, an appropriate escape
function should be applied, e.g. <tt>{{STUDENT_ANSWER | e('py')}}</tt> is the student
answer escaped in a manner suitable for use within Python triple-double-quoted
strings. Other escape functions are <tt>e('c')</tt>, <tt>e('java')</tt>,
<tt>e('matlab')</tt>. The program that is output by Twig is then compiled and executed
with the language of the selected built-in type and with stdin set
to TEST.stdin. Output from that program is then passed to the selected grader.
See the help under 'Grading controls' for more on that.

Note that if a customised per-test template is used
there will be a compile-and-execute cycle for every test case, whereas most
built-in question types define instead a combinator template that combines
all test cases into a single run.

If the template-debugging checkbox is clicked, the program generated
for each testcase will be displayed in the output.";s:14:"templateparams";s:15:"Template params";s:19:"templateparams_help";s:1318:"The template parameters field lets you pass string parameters to a question's
template(s). If non-blank, this must be a JSON-format record. The fields of
the record can then be used within the template, where they appear as
QUESTION.parameters.&lt;&lt;param&gt;&gt;. For example, if template params is

        {"age": 23}

the value 23 would be substituted into the template in place of the
template variable <tt>{{ QUESTION.parameters.age }}</tt>.

The set of template parameters passed to the template consists of any template
parameters defined in the prototype with the question template parameters
merged in. Question parameters can thus override prototype parameters, but not
delete them.

Template parameters can also be used to provide randomisation within a question.
When the question is first instantiated the template parameters are passed
through the Twig template engine to yield the final JSON version.
Twig's "random" function can
be used to assign random values to template parameters. If the "Twig All" checkbox
is checked, all other fields of the question (question text, answer, test cases
etc) are the also processed by Twig, with the template parameters as an
environment. This can result in different
students seeing different random variants of the question. See the documentation
for details.";s:12:"testalltitle";s:34:"Test all questions in this context";s:17:"testallincategory";s:35:"Test all questions in this category";s:8:"testcase";s:14:"Test case {$a}";s:16:"testcasecontrols";s:16:"Test properties:";s:21:"testcasecontrols_help";s:608:"If 'Use as example' is checked, this test will be automatically included in the
question's 'For example:' results table.

The 'Display' combobox determines when this testcase is shown to the student
in the results table.

If 'Hide rest if fail' is checked and this test fails, all subsequent tests will
be hidden from the student, regardless of the setting of the 'Display' combobox.

'Mark' sets the value of this test case; meaningful only if this is not an
'All-or-nothing' question.

'Ordering' can be used to change the order of testcases when the question is
saved: testcases are ordered by this field.";s:9:"testcases";s:10:"Test cases";s:8:"testcode";s:9:"Test code";s:10:"testcolhdr";s:4:"Test";s:15:"testingquestion";s:21:"Testing question {$a}";s:14:"testsplitterre";s:21:"Test splitter (regex)";s:13:"testcode_help";s:64:"The code for the test, seen by the template as {{TEST.testcode}}";s:8:"testtype";s:18:"Precheck test type";s:13:"testtype_help";s:243:"If Prechecking is enabled and set to 'selected', this setting controls whether
the test is used only with a normal run, only with a precheck run or in both runs.
If Prechecking is set to anything other than 'selected', this setting is
ignored.";s:15:"testtype_normal";s:10:"Check only";s:17:"testtype_precheck";s:13:"Precheck only";s:13:"testtype_both";s:4:"Both";s:8:"tooshort";s:73:"Answer is too short to be meaningful and has been ignored without penalty";s:7:"twigall";s:8:"Twig all";s:12:"twigcontrols";s:13:"Twig controls";s:17:"twigcontrols_help";s:673:"Template parameters are normally referred to during Twig expansion in the form
{{QUESTION.parameters.someparam}} However, if the Hoist Template Parameters
checkbox is checked, the parameters are hoisted into the Twig global name space
and can be referenced simply as {{someparam}}.

The Twig macro processor was traditionally applied only to the template. It is now
applied to the template parameters as well and, if Twig All is checked, to the
question text, sample answer, answer preload and all test case fields, using
the Twig-expanded template parameters as an environment. You will usually
need to turn on TwigAll if using randomisation within the template parameters";s:9:"twigerror";s:15:"Twig error {$a}";s:15:"twigerrorintest";s:41:"Twig error when processing this test {$a}";s:11:"type_header";s:24:"CodeRunner question type";s:8:"typename";s:13:"Question type";s:12:"typerequired";s:58:"Please select the type of question (language, format, etc)";s:10:"uicontrols";s:9:"Input UIs";s:15:"uicontrols_help";s:2502:"Select the User Interface controllers for the student answer and
the question author's template.

The Student Answer dropdown displays a list
of available plugins. For coding questions, the Ace editor is usually used.
A value of 'None' can be used to provide just a raw text box. The value
'Graph' provides the user with a simple graph-drawing user-interface for use
with questions that ask the student to draw a graph to some specification; such
questions will usually have a single test case, graded with a template
that analyses the serialised
representation of the graph and prints a message like "OK" if the answer is
correct or a suitably informative error message otherwise.
Template parameters can be set in either the prototype or the
actual question to modify the behaviour of the Graph plugin as follows:
{"isdirected": false} for non-directed graphs, {"isfsm": false} to disallow
incoming edges without a start node (required by Finite State Machine graphs, FSMs),
{"noderadius": 30}, say, to set a different noderadius in pixels.
The template parameters
from the actual question are merged with, and override, those from the
prototype (since CodeRunner V3.2.2).

There is also a 'Table' user interface element, which displays a table of text
areas for the student to
fill in. It is used by the 'python3_program_testing' question type, which is
included in the sample questions on github. This takes template parameters of
table_num_rows and table_num_columns (both required) and optional table_column_headers
(a list of strings with which to label columns), table_row_labels (a list of
strings with which to label rows) and table_column_width_percents (a list of
the percentages of the table width to allocate to all columns, including the
row label column if specified) and table_locked_cells (a list of [row, column]
pairs of cells that the user cannot alter - the row and column indices are
0-origin but do not include the row label column or the column header row).

Students with poor eyesight, or authors wishing to inspect serialisations
(say to understand the representation used by the Graph UI),
can toggle the use of all UI plugins on the current page by typing
Ctrl-Alt-M.

Whatever value is selected for the student answer will also be used within
the editor form for the Sample Answer and the Answer Preload fields.

If 'Template uses ace' is checked,
the Ace code editor will manage both the template and the template parameters
boxes. Otherwise a raw text box will be used.";s:11:"ui_fallback";s:30:"Falling back to raw text area.";s:20:"unauthorisedbulktest";s:59:"You do not have suitable access to any CodeRunner questions";s:20:"unauthoriseddbaccess";s:41:"You are not authorised to use this script";s:12:"unknownerror";s:73:"An unexpected error occurred. The sandbox may be down. Try again shortly.";s:28:"unknowncombinatorgraderfield";s:64:"Unknown field name ({$a->fieldname}) in combinator grader output";s:17:"unserializefailed";s:69:"Stored test results could not be deserialised. Perhaps try regrading?";s:12:"useasexample";s:14:"Use as example";s:6:"useace";s:17:"Template uses ace";s:14:"validateonsave";s:16:"Validate on save";s:20:"wrongnumberofformats";s:83:"Wrong number of test results column formats. Expected {$a->expected}, got {$a->got}";s:24:"xmlcoderunnerformaterror";s:39:"XML format error in coderunner question";}